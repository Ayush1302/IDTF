{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining \n",
    "\n",
    "## Sanjiv R. Das\n",
    "\n",
    "### Reading references\n",
    "\n",
    "- NLTK: http://www.nltk.org/book/\n",
    "- Introduction to Linguistics: http://www.ling.upenn.edu/courses/Fall_2003/ling001/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Text Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Ask not what your country can do for you, \\\n",
    "but ask what you can do for your country.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many characters including blanks? \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ask', 'not', 'what', 'your', 'country', 'can', 'do', 'for', 'you,', 'but', 'ask', 'what', 'you', 'can', 'do', 'for', 'your', 'country.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the words, separating by spaces, periods, commas\n",
    "x = text.split(\" \")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many words?\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this returns words with commas and periods included, which is not desired. So what we need is the regular expressions package, i.e., re. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ask', 'not', 'what', 'your', 'country', 'can', 'do', 'for', 'you', '', 'but', 'ask', 'what', 'you', 'can', 'do', 'for', 'your', 'country', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "x = re.split('[ ,.]',text)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ask', 'not', 'what', 'your', 'country', 'can', 'do', 'for', 'you', 'but', 'ask', 'what', 'you', 'can', 'do', 'for', 'your', 'country']\n"
     ]
    }
   ],
   "source": [
    "#Use a list comprehension to remove spaces\n",
    "x = [j for j in x if len(j)>0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ask' 'but' 'can' 'country' 'do' 'for' 'not' 'what' 'you' 'your']\n"
     ]
    }
   ],
   "source": [
    "#Unique words\n",
    "y = [j.lower() for j in x]\n",
    "z = unique(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using List Comprehensions to find specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'your', 'country', 'what', 'your', 'country']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find words greater than 3 characters\n",
    "[j for j in x if len(j)>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ask']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find capitalized words\n",
    "[j for j in x if j.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'can', 'can', 'country']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find words that begin with c\n",
    "[j for j in x if j.startswith('c')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'what', 'but', 'what']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find words that end in t\n",
    "[j for j in x if j.endswith('t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ask', 'what', 'can', 'ask', 'what', 'can']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find words that contain a\n",
    "[j for j in x if \"a\" in set(j.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, use regular expressions to help us with more complex parsing. \n",
    "\n",
    "For example `'@[A-Za-z0-9_]+'` will return all words that: \n",
    "* start with `'@'` and are followed by at least one: \n",
    "* capital letter (`'A-Z'`)\n",
    "* lowercase letter (`'a-z'`) \n",
    "* number (`'0-9'`)\n",
    "* or underscore (`'_'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ask', 'what', 'can', 'ask', 'what', 'can']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find words that contain 'a' using RE\n",
    "[j for j in x if re.search('[Aa]',j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ask', 'not', 'what', 'your', 'country', 'can', 'do', 'for', 'you', 'but', 'ask', 'what', 'you', 'can', 'do', 'for', 'your', 'country']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['not',\n",
       " 'what',\n",
       " 'your',\n",
       " 'country',\n",
       " 'can',\n",
       " 'do',\n",
       " 'for',\n",
       " 'you',\n",
       " 'but',\n",
       " 'ask',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'do',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test type of tokens\n",
    "print(x)\n",
    "[j for j in x if j.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for j in x if j.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ask',\n",
       " 'not',\n",
       " 'what',\n",
       " 'your',\n",
       " 'country',\n",
       " 'can',\n",
       " 'do',\n",
       " 'for',\n",
       " 'you',\n",
       " 'but',\n",
       " 'ask',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'do',\n",
       " 'for',\n",
       " 'your',\n",
       " 'country']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[j for j in x if j.isalnum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be.\n",
      "  To be or not to be.\n",
      "  to be or not to be.  \n",
      "  TO BE OR NOT TO BE.  \n"
     ]
    }
   ],
   "source": [
    "y = '  To be or not to be.  '\n",
    "print(y.strip())\n",
    "print(y.rstrip())\n",
    "print(y.lower())\n",
    "print(y.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#Return the starting position of the string\n",
    "print(y.find('be'))\n",
    "print(y.rfind('be'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  To do or not to do.  \n"
     ]
    }
   ],
   "source": [
    "print(y.replace('be','do'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Supercal', 'frag', 'l', 'st', 'cexp', 'al', 'doc', 'ous']\n",
      "Supercalifragilisticexpialidocious\n",
      "['S', 'u', 'p', 'e', 'r', 'c', 'a', 'l', 'i', 'f', 'r', 'a', 'g', 'i', 'l', 'i', 's', 't', 'i', 'c', 'e', 'x', 'p', 'i', 'a', 'l', 'i', 'd', 'o', 'c', 'i', 'o', 'u', 's']\n"
     ]
    }
   ],
   "source": [
    "y = 'Supercalifragilisticexpialidocious'\n",
    "ytok = y.split('i')\n",
    "print(ytok)\n",
    "print('i'.join(ytok))\n",
    "print(list(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "<BODY background=\"http://algo.scu.edu/~sanjivdas/graphics/back2.gif\">\n",
      "\n",
      "Sanjiv Das is the William and Janice Terry Professor of Finance and\n",
      "Data Science at Santa Clara University's Leavey School of Business. He\n",
      "previously held faculty appointments as Associate Professor at Harvard\n",
      "Business School and UC Berkeley. He holds post-graduate degrees in\n",
      "Finance (M.Phil and Ph.D. from New York University), Computer Science\n",
      "(M.S. from UC Berkeley), an MBA from the Indian Institute of\n",
      "Management, Ahmedabad, B.Com in Accounting and Economics (University\n",
      "of Bombay, Sydenham College), and is also a qualified Cost and Works\n",
      "Accountant (AICWA). He is a senior editor of The Journal of Investment\n",
      "Management, co-editor of The Journal of Derivatives and The Journal of\n",
      "Financial Services Research, and Associate Editor of other academic\n",
      "journals. Prior to being an academic, he worked in the derivatives\n",
      "business in the Asia-Pacific region as a Vice-President at\n",
      "Citibank. His current research interests include: machine learning,\n",
      "social networks, derivatives pricing models, portfolio theory, the\n",
      "modeling of default risk, systemic risk, and venture capital.  He has\n",
      "published over ninety articles in academic journals, and has won\n",
      "numerous awards for research and teaching. His recent book\n",
      "\"Derivatives: Principles and Practice\" was published in May 2010\n",
      "(second edition 2016).  He currently also serves as a Senior Fellow at\n",
      "the FDIC Center for Financial Research.\n",
      "\n",
      "\n",
      "<p> <B>Sanjiv Das: A Short Academic Life History</B> <p>\n",
      "\n",
      "After loafing and working in many parts of Asia, but never really\n",
      "growing up, Sanjiv moved to New York to change the world, hopefully\n",
      "through research.  He graduated in 1994 with a Ph.D. from NYU, and\n",
      "since then spent five years in Boston, and now lives in San Jose,\n",
      "California.  Sanjiv loves animals, places in the world where the\n",
      "mountains meet the sea, riding sport motorbikes, reading, gadgets,\n",
      "science fiction movies, and writing cool software code. When there is\n",
      "time available from the excitement of daily life, Sanjiv writes\n",
      "academic papers, which helps him relax. Always the contrarian, Sanjiv\n",
      "thinks that New York City is the most calming place in the world,\n",
      "after California of course.\n",
      "\n",
      "<p>\n",
      "\n",
      "Sanjiv is now a Professor of Finance at Santa Clara University. He came\n",
      "to SCU from Harvard Business School and spent a year at UC Berkeley. In\n",
      "his past life in the unreal world, Sanjiv worked at Citibank, N.A. in\n",
      "the Asia-Pacific region. He takes great pleasure in merging his many\n",
      "previous lives into his current existence, which is incredibly confused\n",
      "and diverse.\n",
      "\n",
      "<p>\n",
      "\n",
      "Sanjiv's research style is instilled with a distinct \"New York state of\n",
      "mind\" - it is chaotic, diverse, with minimal method to the madness. He\n",
      "has published articles on derivatives, term-structure models, mutual\n",
      "funds, the internet, portfolio choice, banking models, credit risk, and\n",
      "has unpublished articles in many other areas. Some years ago, he took\n",
      "time off to get another degree in computer science at Berkeley,\n",
      "confirming that an unchecked hobby can quickly become an obsession.\n",
      "There he learnt about the fascinating field of Randomized Algorithms,\n",
      "skills he now applies earnestly to his editorial work, and other\n",
      "pursuits, many of which stem from being in the epicenter of Silicon\n",
      "Valley.\n",
      "\n",
      "<p>\n",
      "\n",
      "Coastal living did a lot to mold Sanjiv, who needs to live near the\n",
      "ocean.  The many walks in Greenwich village convinced him that there is\n",
      "no such thing as a representative investor, yet added many unique\n",
      "features to his personal utility function. He learnt that it is\n",
      "important to open the academic door to the ivory tower and let the world\n",
      "in. Academia is a real challenge, given that he has to reconcile many\n",
      "more opinions than ideas. He has been known to have turned down many\n",
      "offers from Mad magazine to publish his academic work. As he often\n",
      "explains, you never really finish your education - \"you can check out\n",
      "any time you like, but you can never leave.\" Which is why he is doomed\n",
      "to a lifetime in Hotel California. And he believes that, if this is as\n",
      "bad as it gets, life is really pretty good.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Reading in a URL\n",
    "import requests\n",
    "\n",
    "url = 'http://srdas.github.io/bio-candid.html'\n",
    "f = requests.get(url)\n",
    "text = f.text\n",
    "print(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Sanjiv Das is the William and Janice Terry Professor of Finance and\n"
     ]
    }
   ],
   "source": [
    "lines = text.splitlines()\n",
    "print(len(lines))\n",
    "print(lines[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BS to clean up all the html stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Sanjiv Das is the William and Janice Terry Professor of Finance and\n",
      "Data Science at Santa Clara University's Leavey School of Business. He\n",
      "previously held faculty appointments as Associate Professor at Harvard\n",
      "Business School and UC Berkeley. He holds post-graduate degrees in\n",
      "Finance (M.Phil and Ph.D. from New York University), Computer Science\n",
      "(M.S. from UC Berkeley), an MBA from the Indian Institute of\n",
      "Management, Ahmedabad, B.Com in Accounting and Economics (University\n",
      "of Bombay, Sydenham College), and is also a qualified Cost and Works\n",
      "Accountant (AICWA). He is a senior editor of The Journal of Investment\n",
      "Management, co-editor of The Journal of Derivatives and The Journal of\n",
      "Financial Services Research, and Associate Editor of other academic\n",
      "journals. Prior to being an academic, he worked in the derivatives\n",
      "business in the Asia-Pacific region as a Vice-President at\n",
      "Citibank. His current research interests include: machine learning,\n",
      "social networks, derivatives pricing models, portfolio theory, the\n",
      "modeling of default risk, systemic risk, and venture capital.  He has\n",
      "published over ninety articles in academic journals, and has won\n",
      "numerous awards for research and teaching. His recent book\n",
      "\"Derivatives: Principles and Practice\" was published in May 2010\n",
      "(second edition 2016).  He currently also serves as a Senior Fellow at\n",
      "the FDIC Center for Financial Research.\n",
      "\n",
      "\n",
      " Sanjiv Das: A Short Academic Life History \n",
      "\n",
      "After loafing and working in many parts of Asia, but never really\n",
      "growing up, Sanjiv moved to New York to change the world, hopefully\n",
      "through research.  He graduated in 1994 with a Ph.D. from NYU, and\n",
      "since then spent five years in Boston, and now lives in San Jose,\n",
      "California.  Sanjiv loves animals, places in the world where the\n",
      "mountains meet the sea, riding sport motorbikes, reading, gadgets,\n",
      "science fiction movies, and writing cool software code. When there is\n",
      "time available from the excitement of daily life, Sanjiv writes\n",
      "academic papers, which helps him relax. Always the contrarian, Sanjiv\n",
      "thinks that New York City is the most calming place in the world,\n",
      "after California of course.\n",
      "\n",
      "\n",
      "\n",
      "Sanjiv is now a Professor of Finance at Santa Clara University. He came\n",
      "to SCU from Harvard Business School and spent a year at UC Berkeley. In\n",
      "his past life in the unreal world, Sanjiv worked at Citibank, N.A. in\n",
      "the Asia-Pacific region. He takes great pleasure in merging his many\n",
      "previous lives into his current existence, which is incredibly confused\n",
      "and diverse.\n",
      "\n",
      "\n",
      "\n",
      "Sanjiv's research style is instilled with a distinct \"New York state of\n",
      "mind\" - it is chaotic, diverse, with minimal method to the madness. He\n",
      "has published articles on derivatives, term-structure models, mutual\n",
      "funds, the internet, portfolio choice, banking models, credit risk, and\n",
      "has unpublished articles in many other areas. Some years ago, he took\n",
      "time off to get another degree in computer science at Berkeley,\n",
      "confirming that an unchecked hobby can quickly become an obsession.\n",
      "There he learnt about the fascinating field of Randomized Algorithms,\n",
      "skills he now applies earnestly to his editorial work, and other\n",
      "pursuits, many of which stem from being in the epicenter of Silicon\n",
      "Valley.\n",
      "\n",
      "\n",
      "\n",
      "Coastal living did a lot to mold Sanjiv, who needs to live near the\n",
      "ocean.  The many walks in Greenwich village convinced him that there is\n",
      "no such thing as a representative investor, yet added many unique\n",
      "features to his personal utility function. He learnt that it is\n",
      "important to open the academic door to the ivory tower and let the world\n",
      "in. Academia is a real challenge, given that he has to reconcile many\n",
      "more opinions than ideas. He has been known to have turned down many\n",
      "offers from Mad magazine to publish his academic work. As he often\n",
      "explains, you never really finish your education - \"you can check out\n",
      "any time you like, but you can never leave.\" Which is why he is doomed\n",
      "to a lifetime in Hotel California. And he believes that, if this is as\n",
      "bad as it gets, life is really pretty good.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "sanjivbio = BeautifulSoup(text,'lxml').get_text()\n",
    "print(sanjivbio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sanjivbio))\n",
    "type(sanjivbio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entryword Source Pos Neg Pstv Affil Ngtv Hostile Strng Power Weak Subm Actv Psv Pleasure Pain Arousal EMOT Feel Virtue Vice Ovrst Undrst Acad Doctr Econ* Exch ECON Exprs Legal Milit Polit* POLIT Relig Role COLL Work Ritual Intrel Race Kin* MALE Female Nonadlt HU ANI PLACE Social Region Route Aquatic Land Sky Object Tool Food Vehicle Bldgpt Natobj Bodypt Comnobj Comform COM Say Need Goal Try Means Ach Persist Complt Fail Natpro Begin Vary Change Incr Decr Finish Stay Rise Move Exert Fetch Travel Fall Think Know Causal Ought Percv Comp Eval EVAL Solve Abs* ABS Qual Quan NUMB ORD CARD FREQ DIST Time* TIME Space POS DIM Dimn Rel COLOR Self Our You Name Yes No Negate Intrj IAV DAV SV IPadj IndAdj POWGAIN POWLOSS POWENDS POWAREN POWCON POWCOOP POWAPT POWPT POWDOCT POWAUTH POWOTH POWTOT RCTETH RCTREL RCTGAIN RCTLOSS RCTENDS RCTTOT RSPGAIN RSPLOSS RSPOTH RSPTOT AFFGAIN AFFLOSS AFFPT AFFOTH AFFTOT WLTPT WLTTRAN WLTOTH WLTTOT WLBGAIN WLBLOSS WLBPHYS WLBPSYC WLBPT WLBTOT ENLGAIN ENLLOSS ENLENDS ENLPT ENLOTH ENLTOT SKLAS SKLPT SKLOTH SKLTOT TRNGAIN TRNLOSS TRANS MEANS ENDS ARENAS PARTIC NATIONS AUD ANOMIE NEGAFF POSAFF SURE IF NOT TIMESP FOOD FORM Othertags Definition ',\n",
       " 'A H4Lvd DET ART  | article: Indefinite singular article--some or any one',\n",
       " 'ABANDON H4Lvd Neg Ngtv Weak Fail IAV AFFLOSS AFFTOT SUPV  |',\n",
       " 'ABANDONMENT H4 Neg Weak Fail Noun  |',\n",
       " 'ABATE H4Lvd Neg Psv Decr IAV TRANS SUPV  |',\n",
       " 'ABATEMENT Lvd Noun  ',\n",
       " 'ABDICATE H4 Neg Weak Subm Psv Finish IAV SUPV  |',\n",
       " 'ABHOR H4 Neg Hostile Psv Arousal SV SUPV  |',\n",
       " 'ABIDE H4 Pos Affil Actv Doctr IAV SUPV  |',\n",
       " 'ABIDE#1 Lvd Modif  ',\n",
       " 'ABIDE#2 Lvd SUPV  ',\n",
       " 'ABILITY Lvd MEANS Noun ABS ABS*  ',\n",
       " 'ABJECT H4 Neg Weak Subm Psv Vice IPadj Modif  |',\n",
       " 'ABLE H4Lvd Pos Pstv Strng Virtue EVAL MEANS Modif  | adjective: Having necessary power, skill, resources, etc.',\n",
       " 'ABNORMAL H4Lvd Neg Ngtv Vice NEGAFF Modif  |',\n",
       " 'ABOARD H4Lvd Space PREP LY  |',\n",
       " 'ABOLISH H4Lvd Neg Ngtv Hostile Strng Power Actv Intrel IAV POWOTH POWTOT SUPV  |',\n",
       " 'ABOLITION Lvd TRANS Noun  ',\n",
       " 'ABOMINABLE H4 Neg Strng Vice Ovrst Eval IndAdj Modif  |',\n",
       " 'ABORTIVE Lvd POWOTH POWTOT Modif POLIT  ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in a file\n",
    "## Here we will read in an entire dictionary from Harvard Inquirer\n",
    "\n",
    "f = open('inqdict.txt')\n",
    "HIDict = f.read()\n",
    "HIDict = HIDict.splitlines()\n",
    "HIDict[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sentiment Score the Text using this Dictionary from Harvard Inquirer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABOLISH H4Lvd Neg Ngtv Hostile Strng Power Actv Intrel IAV POWOTH POWTOT SUPV  |', 'ABOLITION Lvd TRANS Noun  ', 'ABOMINABLE H4 Neg Strng Vice Ovrst Eval IndAdj Modif  |', 'ABORTIVE Lvd POWOTH POWTOT Modif POLIT  ', 'ABOUND H4 Pos Psv Incr IAV SUPV  |']\n",
      "11880\n",
      "['abound', 'absolve', 'absorbent', 'absorption', 'abundance', 'abundant', 'accede', 'accentuate', 'accept', 'acceptable', 'acceptance', 'accessible', 'accession', 'acclaim', 'acclamation', 'accolade', 'accommodate', 'accommodation', 'accompaniment', 'accomplish']\n",
      "1644\n"
     ]
    }
   ],
   "source": [
    "#Extract all the lines that contain the Pos tag\n",
    "HIDict = HIDict[1:]\n",
    "print(HIDict[:5])\n",
    "print(len(HIDict))\n",
    "poswords = [j for j in HIDict if \"Pos\" in j]  #using a list comprehension\n",
    "poswords = [j.split()[0] for j in poswords]\n",
    "poswords = [j.split(\"#\")[0] for j in poswords]\n",
    "poswords = unique(poswords)\n",
    "poswords = [j.lower() for j in poswords]\n",
    "print(poswords[:20])\n",
    "print(len(poswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abolish', 'abominable', 'abrasive', 'abrupt', 'abscond', 'absence', 'absent', 'absent-minded', 'absentee', 'absurd', 'absurdity', 'abuse', 'abyss', 'accident', 'accost', 'account', 'accursed', 'accusation', 'accuse', 'ache']\n",
      "2113\n"
     ]
    }
   ],
   "source": [
    "#Extract all the lines that contain the Neg tag\n",
    "negwords = [j for j in HIDict if \"Neg\" in j]  #using a list comprehension\n",
    "negwords = [j.split()[0] for j in negwords]\n",
    "negwords = [j.split(\"#\")[0] for j in negwords]\n",
    "negwords = unique(negwords)\n",
    "negwords = [j.lower() for j in negwords]\n",
    "print(negwords[:20])\n",
    "print(len(negwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   sanjiv das is the william and janice terry professor of finance and data science at santa clara university\\'s leavey school of business. he previously held faculty appointments as associate professor at harvard business school and uc berkeley. he holds post-graduate degrees in finance (m.phil and ph.d. from new york university), computer science (m.s. from uc berkeley), an mba from the indian institute of management, ahmedabad, b.com in accounting and economics (university of bombay, sydenham college), and is also a qualified cost and works accountant (aicwa). he is a senior editor of the journal of investment management, co-editor of the journal of derivatives and the journal of financial services research, and associate editor of other academic journals. prior to being an academic, he worked in the derivatives business in the asia-pacific region as a vice-president at citibank. his current research interests include: machine learning, social networks, derivatives pricing models, portfolio theory, the modeling of default risk, systemic risk, and venture capital.  he has published over ninety articles in academic journals, and has won numerous awards for research and teaching. his recent book \"derivatives: principles and practice\" was published in may 2010 (second edition 2016).  he currently also serves as a senior fellow at the fdic center for financial research.    sanjiv das: a short academic life history   after loafing and working in many parts of asia, but never really growing up, sanjiv moved to new york to change the world, hopefully through research.  he graduated in 1994 with a ph.d. from nyu, and since then spent five years in boston, and now lives in san jose, california.  sanjiv loves animals, places in the world where the mountains meet the sea, riding sport motorbikes, reading, gadgets, science fiction movies, and writing cool software code. when there is time available from the excitement of daily life, sanjiv writes academic papers, which helps him relax. always the contrarian, sanjiv thinks that new york city is the most calming place in the world, after california of course.    sanjiv is now a professor of finance at santa clara university. he came to scu from harvard business school and spent a year at uc berkeley. in his past life in the unreal world, sanjiv worked at citibank, n.a. in the asia-pacific region. he takes great pleasure in merging his many previous lives into his current existence, which is incredibly confused and diverse.    sanjiv\\'s research style is instilled with a distinct \"new york state of mind\" - it is chaotic, diverse, with minimal method to the madness. he has published articles on derivatives, term-structure models, mutual funds, the internet, portfolio choice, banking models, credit risk, and has unpublished articles in many other areas. some years ago, he took time off to get another degree in computer science at berkeley, confirming that an unchecked hobby can quickly become an obsession. there he learnt about the fascinating field of randomized algorithms, skills he now applies earnestly to his editorial work, and other pursuits, many of which stem from being in the epicenter of silicon valley.    coastal living did a lot to mold sanjiv, who needs to live near the ocean.  the many walks in greenwich village convinced him that there is no such thing as a representative investor, yet added many unique features to his personal utility function. he learnt that it is important to open the academic door to the ivory tower and let the world in. academia is a real challenge, given that he has to reconcile many more opinions than ideas. he has been known to have turned down many offers from mad magazine to publish his academic work. as he often explains, you never really finish your education - \"you can check out any time you like, but you can never leave.\" which is why he is doomed to a lifetime in hotel california. and he believes that, if this is as bad as it gets, life is really pretty good.    '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pull clean lowercase version of bio as one long string\n",
    "text = sanjivbio.replace('\\n',' ').lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " 'sanjiv',\n",
       " 'das',\n",
       " 'is',\n",
       " 'the',\n",
       " 'william',\n",
       " 'and',\n",
       " 'janice',\n",
       " 'terry',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'finance',\n",
       " 'and',\n",
       " 'data',\n",
       " 'science',\n",
       " 'at',\n",
       " 'santa',\n",
       " 'clara',\n",
       " \"university's\",\n",
       " 'leavey',\n",
       " 'school',\n",
       " 'of',\n",
       " 'business.',\n",
       " 'he',\n",
       " 'previously',\n",
       " 'held',\n",
       " 'faculty',\n",
       " 'appointments',\n",
       " 'as',\n",
       " 'associate',\n",
       " 'professor',\n",
       " 'at',\n",
       " 'harvard',\n",
       " 'business',\n",
       " 'school',\n",
       " 'and',\n",
       " 'uc',\n",
       " 'berkeley.',\n",
       " 'he',\n",
       " 'holds',\n",
       " 'post-graduate',\n",
       " 'degrees',\n",
       " 'in',\n",
       " 'finance',\n",
       " '(m.phil',\n",
       " 'and',\n",
       " 'ph.d.',\n",
       " 'from',\n",
       " 'new',\n",
       " 'york',\n",
       " 'university),',\n",
       " 'computer',\n",
       " 'science',\n",
       " '(m.s.',\n",
       " 'from',\n",
       " 'uc',\n",
       " 'berkeley),',\n",
       " 'an',\n",
       " 'mba',\n",
       " 'from',\n",
       " 'the',\n",
       " 'indian',\n",
       " 'institute',\n",
       " 'of',\n",
       " 'management,',\n",
       " 'ahmedabad,',\n",
       " 'b.com',\n",
       " 'in',\n",
       " 'accounting',\n",
       " 'and',\n",
       " 'economics',\n",
       " '(university',\n",
       " 'of',\n",
       " 'bombay,',\n",
       " 'sydenham',\n",
       " 'college),',\n",
       " 'and',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'qualified',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'works',\n",
       " 'accountant',\n",
       " '(aicwa).',\n",
       " 'he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'senior',\n",
       " 'editor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'journal',\n",
       " 'of',\n",
       " 'investment',\n",
       " 'management,',\n",
       " 'co-editor',\n",
       " 'of',\n",
       " 'the',\n",
       " 'journal',\n",
       " 'of',\n",
       " 'derivatives',\n",
       " 'and',\n",
       " 'the',\n",
       " 'journal',\n",
       " 'of',\n",
       " 'financial',\n",
       " 'services',\n",
       " 'research,',\n",
       " 'and',\n",
       " 'associate',\n",
       " 'editor',\n",
       " 'of',\n",
       " 'other',\n",
       " 'academic',\n",
       " 'journals.',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'being',\n",
       " 'an',\n",
       " 'academic,',\n",
       " 'he',\n",
       " 'worked',\n",
       " 'in',\n",
       " 'the',\n",
       " 'derivatives',\n",
       " 'business',\n",
       " 'in',\n",
       " 'the',\n",
       " 'asia-pacific',\n",
       " 'region',\n",
       " 'as',\n",
       " 'a',\n",
       " 'vice-president',\n",
       " 'at',\n",
       " 'citibank.',\n",
       " 'his',\n",
       " 'current',\n",
       " 'research',\n",
       " 'interests',\n",
       " 'include:',\n",
       " 'machine',\n",
       " 'learning,',\n",
       " 'social',\n",
       " 'networks,',\n",
       " 'derivatives',\n",
       " 'pricing',\n",
       " 'models,',\n",
       " 'portfolio',\n",
       " 'theory,',\n",
       " 'the',\n",
       " 'modeling',\n",
       " 'of',\n",
       " 'default',\n",
       " 'risk,',\n",
       " 'systemic',\n",
       " 'risk,',\n",
       " 'and',\n",
       " 'venture',\n",
       " 'capital.',\n",
       " '',\n",
       " 'he',\n",
       " 'has',\n",
       " 'published',\n",
       " 'over',\n",
       " 'ninety',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'academic',\n",
       " 'journals,',\n",
       " 'and',\n",
       " 'has',\n",
       " 'won',\n",
       " 'numerous',\n",
       " 'awards',\n",
       " 'for',\n",
       " 'research',\n",
       " 'and',\n",
       " 'teaching.',\n",
       " 'his',\n",
       " 'recent',\n",
       " 'book',\n",
       " '\"derivatives:',\n",
       " 'principles',\n",
       " 'and',\n",
       " 'practice\"',\n",
       " 'was',\n",
       " 'published',\n",
       " 'in',\n",
       " 'may',\n",
       " '2010',\n",
       " '(second',\n",
       " 'edition',\n",
       " '2016).',\n",
       " '',\n",
       " 'he',\n",
       " 'currently',\n",
       " 'also',\n",
       " 'serves',\n",
       " 'as',\n",
       " 'a',\n",
       " 'senior',\n",
       " 'fellow',\n",
       " 'at',\n",
       " 'the',\n",
       " 'fdic',\n",
       " 'center',\n",
       " 'for',\n",
       " 'financial',\n",
       " 'research.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sanjiv',\n",
       " 'das:',\n",
       " 'a',\n",
       " 'short',\n",
       " 'academic',\n",
       " 'life',\n",
       " 'history',\n",
       " '',\n",
       " '',\n",
       " 'after',\n",
       " 'loafing',\n",
       " 'and',\n",
       " 'working',\n",
       " 'in',\n",
       " 'many',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'asia,',\n",
       " 'but',\n",
       " 'never',\n",
       " 'really',\n",
       " 'growing',\n",
       " 'up,',\n",
       " 'sanjiv',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'new',\n",
       " 'york',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'world,',\n",
       " 'hopefully',\n",
       " 'through',\n",
       " 'research.',\n",
       " '',\n",
       " 'he',\n",
       " 'graduated',\n",
       " 'in',\n",
       " '1994',\n",
       " 'with',\n",
       " 'a',\n",
       " 'ph.d.',\n",
       " 'from',\n",
       " 'nyu,',\n",
       " 'and',\n",
       " 'since',\n",
       " 'then',\n",
       " 'spent',\n",
       " 'five',\n",
       " 'years',\n",
       " 'in',\n",
       " 'boston,',\n",
       " 'and',\n",
       " 'now',\n",
       " 'lives',\n",
       " 'in',\n",
       " 'san',\n",
       " 'jose,',\n",
       " 'california.',\n",
       " '',\n",
       " 'sanjiv',\n",
       " 'loves',\n",
       " 'animals,',\n",
       " 'places',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'where',\n",
       " 'the',\n",
       " 'mountains',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'sea,',\n",
       " 'riding',\n",
       " 'sport',\n",
       " 'motorbikes,',\n",
       " 'reading,',\n",
       " 'gadgets,',\n",
       " 'science',\n",
       " 'fiction',\n",
       " 'movies,',\n",
       " 'and',\n",
       " 'writing',\n",
       " 'cool',\n",
       " 'software',\n",
       " 'code.',\n",
       " 'when',\n",
       " 'there',\n",
       " 'is',\n",
       " 'time',\n",
       " 'available',\n",
       " 'from',\n",
       " 'the',\n",
       " 'excitement',\n",
       " 'of',\n",
       " 'daily',\n",
       " 'life,',\n",
       " 'sanjiv',\n",
       " 'writes',\n",
       " 'academic',\n",
       " 'papers,',\n",
       " 'which',\n",
       " 'helps',\n",
       " 'him',\n",
       " 'relax.',\n",
       " 'always',\n",
       " 'the',\n",
       " 'contrarian,',\n",
       " 'sanjiv',\n",
       " 'thinks',\n",
       " 'that',\n",
       " 'new',\n",
       " 'york',\n",
       " 'city',\n",
       " 'is',\n",
       " 'the',\n",
       " 'most',\n",
       " 'calming',\n",
       " 'place',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world,',\n",
       " 'after',\n",
       " 'california',\n",
       " 'of',\n",
       " 'course.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sanjiv',\n",
       " 'is',\n",
       " 'now',\n",
       " 'a',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'finance',\n",
       " 'at',\n",
       " 'santa',\n",
       " 'clara',\n",
       " 'university.',\n",
       " 'he',\n",
       " 'came',\n",
       " 'to',\n",
       " 'scu',\n",
       " 'from',\n",
       " 'harvard',\n",
       " 'business',\n",
       " 'school',\n",
       " 'and',\n",
       " 'spent',\n",
       " 'a',\n",
       " 'year',\n",
       " 'at',\n",
       " 'uc',\n",
       " 'berkeley.',\n",
       " 'in',\n",
       " 'his',\n",
       " 'past',\n",
       " 'life',\n",
       " 'in',\n",
       " 'the',\n",
       " 'unreal',\n",
       " 'world,',\n",
       " 'sanjiv',\n",
       " 'worked',\n",
       " 'at',\n",
       " 'citibank,',\n",
       " 'n.a.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'asia-pacific',\n",
       " 'region.',\n",
       " 'he',\n",
       " 'takes',\n",
       " 'great',\n",
       " 'pleasure',\n",
       " 'in',\n",
       " 'merging',\n",
       " 'his',\n",
       " 'many',\n",
       " 'previous',\n",
       " 'lives',\n",
       " 'into',\n",
       " 'his',\n",
       " 'current',\n",
       " 'existence,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'incredibly',\n",
       " 'confused',\n",
       " 'and',\n",
       " 'diverse.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"sanjiv's\",\n",
       " 'research',\n",
       " 'style',\n",
       " 'is',\n",
       " 'instilled',\n",
       " 'with',\n",
       " 'a',\n",
       " 'distinct',\n",
       " '\"new',\n",
       " 'york',\n",
       " 'state',\n",
       " 'of',\n",
       " 'mind\"',\n",
       " '-',\n",
       " 'it',\n",
       " 'is',\n",
       " 'chaotic,',\n",
       " 'diverse,',\n",
       " 'with',\n",
       " 'minimal',\n",
       " 'method',\n",
       " 'to',\n",
       " 'the',\n",
       " 'madness.',\n",
       " 'he',\n",
       " 'has',\n",
       " 'published',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'derivatives,',\n",
       " 'term-structure',\n",
       " 'models,',\n",
       " 'mutual',\n",
       " 'funds,',\n",
       " 'the',\n",
       " 'internet,',\n",
       " 'portfolio',\n",
       " 'choice,',\n",
       " 'banking',\n",
       " 'models,',\n",
       " 'credit',\n",
       " 'risk,',\n",
       " 'and',\n",
       " 'has',\n",
       " 'unpublished',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'many',\n",
       " 'other',\n",
       " 'areas.',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago,',\n",
       " 'he',\n",
       " 'took',\n",
       " 'time',\n",
       " 'off',\n",
       " 'to',\n",
       " 'get',\n",
       " 'another',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'at',\n",
       " 'berkeley,',\n",
       " 'confirming',\n",
       " 'that',\n",
       " 'an',\n",
       " 'unchecked',\n",
       " 'hobby',\n",
       " 'can',\n",
       " 'quickly',\n",
       " 'become',\n",
       " 'an',\n",
       " 'obsession.',\n",
       " 'there',\n",
       " 'he',\n",
       " 'learnt',\n",
       " 'about',\n",
       " 'the',\n",
       " 'fascinating',\n",
       " 'field',\n",
       " 'of',\n",
       " 'randomized',\n",
       " 'algorithms,',\n",
       " 'skills',\n",
       " 'he',\n",
       " 'now',\n",
       " 'applies',\n",
       " 'earnestly',\n",
       " 'to',\n",
       " 'his',\n",
       " 'editorial',\n",
       " 'work,',\n",
       " 'and',\n",
       " 'other',\n",
       " 'pursuits,',\n",
       " 'many',\n",
       " 'of',\n",
       " 'which',\n",
       " 'stem',\n",
       " 'from',\n",
       " 'being',\n",
       " 'in',\n",
       " 'the',\n",
       " 'epicenter',\n",
       " 'of',\n",
       " 'silicon',\n",
       " 'valley.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'coastal',\n",
       " 'living',\n",
       " 'did',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'mold',\n",
       " 'sanjiv,',\n",
       " 'who',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'live',\n",
       " 'near',\n",
       " 'the',\n",
       " 'ocean.',\n",
       " '',\n",
       " 'the',\n",
       " 'many',\n",
       " 'walks',\n",
       " 'in',\n",
       " 'greenwich',\n",
       " 'village',\n",
       " 'convinced',\n",
       " 'him',\n",
       " 'that',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'such',\n",
       " 'thing',\n",
       " 'as',\n",
       " 'a',\n",
       " 'representative',\n",
       " 'investor,',\n",
       " 'yet',\n",
       " 'added',\n",
       " 'many',\n",
       " 'unique',\n",
       " 'features',\n",
       " 'to',\n",
       " 'his',\n",
       " 'personal',\n",
       " 'utility',\n",
       " 'function.',\n",
       " 'he',\n",
       " 'learnt',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'important',\n",
       " 'to',\n",
       " 'open',\n",
       " 'the',\n",
       " 'academic',\n",
       " 'door',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ivory',\n",
       " 'tower',\n",
       " 'and',\n",
       " 'let',\n",
       " 'the',\n",
       " 'world',\n",
       " 'in.',\n",
       " 'academia',\n",
       " 'is',\n",
       " 'a',\n",
       " 'real',\n",
       " 'challenge,',\n",
       " 'given',\n",
       " 'that',\n",
       " 'he',\n",
       " 'has',\n",
       " 'to',\n",
       " 'reconcile',\n",
       " 'many',\n",
       " 'more',\n",
       " 'opinions',\n",
       " 'than',\n",
       " 'ideas.',\n",
       " 'he',\n",
       " 'has',\n",
       " 'been',\n",
       " 'known',\n",
       " 'to',\n",
       " 'have',\n",
       " 'turned',\n",
       " 'down',\n",
       " 'many',\n",
       " 'offers',\n",
       " 'from',\n",
       " 'mad',\n",
       " 'magazine',\n",
       " 'to',\n",
       " 'publish',\n",
       " 'his',\n",
       " 'academic',\n",
       " 'work.',\n",
       " 'as',\n",
       " 'he',\n",
       " 'often',\n",
       " 'explains,',\n",
       " 'you',\n",
       " 'never',\n",
       " 'really',\n",
       " 'finish',\n",
       " 'your',\n",
       " 'education',\n",
       " '-',\n",
       " '\"you',\n",
       " 'can',\n",
       " 'check',\n",
       " 'out',\n",
       " 'any',\n",
       " 'time',\n",
       " 'you',\n",
       " 'like,',\n",
       " 'but',\n",
       " 'you',\n",
       " 'can',\n",
       " 'never',\n",
       " 'leave.\"',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'he',\n",
       " 'is',\n",
       " 'doomed',\n",
       " 'to',\n",
       " 'a',\n",
       " 'lifetime',\n",
       " 'in',\n",
       " 'hotel',\n",
       " 'california.',\n",
       " 'and',\n",
       " 'he',\n",
       " 'believes',\n",
       " 'that,',\n",
       " 'if',\n",
       " 'this',\n",
       " 'is',\n",
       " 'as',\n",
       " 'bad',\n",
       " 'as',\n",
       " 'it',\n",
       " 'gets,',\n",
       " 'life',\n",
       " 'is',\n",
       " 'really',\n",
       " 'pretty',\n",
       " 'good.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.split(' ')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fellow', 'real', 'reconcile', 'your', 'pleasure', 'important', 'pretty', 'live', 'his', 'distinct', 'associate', 'mutual', 'credit', 'excitement', 'great', 'open', 'have', 'education', 'meet', 'unique'}\n",
      "20\n",
      "{'bad', 'no', 'short', 'cool', 'never', 'unchecked', 'cost', 'default', 'get', 'unreal', 'let', 'mad'}\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Match text to poswords, negwords, use the set operators\n",
    "posmatches = set(text).intersection(set(poswords))\n",
    "print(posmatches)\n",
    "print(len(posmatches))\n",
    "negmatches = set(text).intersection(set(negwords))\n",
    "print(negmatches)\n",
    "print(len(negmatches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Function to Pull Financial Text and score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finScore(url,poswords,negwords):\n",
    "    f = requests.get(url)\n",
    "    text = f.text\n",
    "    f.close()\n",
    "    text = BeautifulSoup(text,'lxml').get_text()    \n",
    "    text = text.replace('\\n',' ').lower()\n",
    "    text = text.split(' ')\n",
    "    posmatches = set(text).intersection(set(poswords))\n",
    "    print(posmatches)\n",
    "    print(len(posmatches))\n",
    "    negmatches = set(text).intersection(set(negwords))\n",
    "    print(negmatches)\n",
    "    print(len(negmatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fellow', 'real', 'reconcile', 'your', 'pleasure', 'important', 'pretty', 'live', 'his', 'distinct', 'associate', 'mutual', 'credit', 'excitement', 'great', 'open', 'have', 'education', 'meet', 'unique'}\n",
      "20\n",
      "{'bad', 'no', 'short', 'cool', 'never', 'unchecked', 'cost', 'default', 'get', 'unreal', 'let', 'mad'}\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Try this on the same data as before\n",
    "url = 'http://srdas.github.io/bio-candid.html'\n",
    "finScore(url,poswords,negwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'integrity', 'comprehensive', 'unlimited', 'enhance', 'accordance', 'travel', 'indicative', 'reward', 'relevant', 'favorable', 'supreme', 'award', 'particular', 'achieve', 'secure', 'justice', 'understood', 'continuity', 'competence', 'persuasive', 'offer', 'pro', 'credit', 'complement', 'extraordinary', 'acceptable', 'safe', 'adjustment', 'maturity', 'success', 'useful', 'interest', 'attract', 'protect', 'responsibility', 'create', 'principal', 'allowance', 'back', 'relief', 'home', 'appoint', 'conjunction', 'even', 'best', 'major', 'have', 'facilitate', 'law', 'engage', 'survive', 'aggregate', 'her', 'security', 'precedent', 'their', 'sensitivity', 'intelligent', 'profit', 'essential', 'important', 'defend', 'support', 'effectiveness', 'fitness', 'educational', 'guarantee', 'satisfaction', 'asset', 'gain', 'renewal', 'responsible', 'commitment', 'compliance', 'assist', 'effective', 'portable', 'knowledge', 'upgrade', 'independent', 'help', 'capability', 'actual', 'compensation', 'bonus', 'free', 'behalf', 'protection', 'commission', 'devote', 'productivity', 'allow', 'better', 'enable', 'consideration', 'contribution', 'privacy', 'definitive', 'merit', 'kind', 'basic', 'trust', 'mutual', 'company', 'advance', 'consistent', 'office', 'practical', 'redemption', 'advisable', 'open', 'offset', 'commencement', 'ensure', 'proprietary', 'adjust', 'communicate', 'dynamic', 'respect', 'lead', 'partner', 'assurance', 'consider', 'objective', 'normal', 'benefit', 'satisfy', 'traditional', 'desirable', 'generate', 'successful', 'permit', 'beneficiary', 'solution', 'adequate', 'attractive', 'suitable', 'collaborate', 'faith', 'equity', 'redeem', 'repair', 'awareness', 'approval', 'settle', 'light', 'safety', 'quality', 'equitable', 'agreement', 'opportunity', 'clarity', 'well', 'natural', 'share', 'measurable', 'community', 'utilize', 'our', 'sufficient', 'superior', 'resolved', 'intellectual', 'aid', 'reasonable', 'sophisticated', 'super', 'lawful', 'gift', 'forward', 'advantage', 'make', 'confer', 'good', 'outstanding', 'return', 'achievement', 'content', 'appropriate', 'consent', 'reliability', 'assure', 'experience', 'virtue', 'buy', 'harmless', 'reconciliation', 'pay', 'favor', 'innovative', 'competent', 'accept', 'fair', 'proactive', 'reconcile', 'appreciation', 'logic', 'your', 'obtain', 'legal', 'approach', 'meaningful', 'improvement', 'order', 'give', 'resolve', 'regard', 'common', 'assistance', 'education', 'confidence', 'compatible', 'unique', 'premium', 'reliable', 'qualify', 'establish', 'subsidize', 'understand', 'simplify', 'capacity', 'health', 'right', 'promptly', 'stimulate', 'sensitive', 'value', 'primarily', 'necessarily', 'marital', 'advantageous', 'board', 'jointly', 'discretion', 'attainment', 'provide', 'meet', 'conclusive', 'availability', 'real', 'arisen', 'contact', 'his', 'significant', 'positive', 'satisfactory', 'preference', 'beneficial', 'matter', 'accomplish', 'improve', 'post', 'my', 'authority'}\n",
      "254\n",
      "{'lose', 'restrict', 'unlimited', 'crime', 'loss', 'capital', 'absence', 'exception', 'decline', 'invalid', 'exempt', 'impossible', 'particular', 'unqualified', 'serve', 'unforeseen', 'withheld', 'competitive', 'against', 'disruption', 'violation', 'poor', 'compete', 'fail', 'unable', 'least', 'nor', 'service', 'violate', 'risky', 'even', 'uncertain', 'mean', 'liquidation', 'instability', 'impede', 'shell', 'nothing', 'volatile', 'rather', 'foreign', 'differ', 'competition', 'suffer', 'cancellation', 'damage', 'interruption', 'no', 'omission', 'force', 'conflict', 'severe', 'help', 'fix', 'disaster', 'bankruptcy', 'expense', 'cut', 'defect', 'indefinite', 'negative', 'decrease', 'adverse', 'impair', 'dispute', 'close', 'inconsistency', 'harm', 'doubtful', 'press', 'turmoil', 'impose', 'difficult', 'malicious', 'intangible', 'lost', 'redundancy', 'refuse', 'interfere', 'liability', 'execute', 'vice', 'failure', 'ambiguity', 'expose', 'complex', 'point', 'division', 'infringement', 'bound', 'illegal', 'unfavorable', 'low', 'not', 'stringent', 'distracting', 'cost', 'terrorism', 'abrupt', 'excess', 'substitution', 'unconditional', 'accident', 'dissolution', 'breach', 'account', 'delinquent', 'ineffective', 'obsolete', 'resignation', 'split', 'exclusion', 'make', 'distraction', 'dissatisfied', 'unusual', 'indirect', 'tax', 'avoid', 'depreciation', 'volatility', 'suspend', 'shortage', 'none', 'raise', 'limitation', 'black', 'suspension', 'sentence', 'lower', 'need', 'prohibitive', 'order', 'unexpected', 'liable', 'cannot', 'death', 'revoke', 'aggressive', 'regardless', 'fall', 'charge', 'withhold', 'involve', 'inadequate', 'eliminate', 'commit', 'neither', 'show', 'short', 'unpredictable', 'hedge', 'unspecified', 'inability', 'discount', 'suspicious', 'untrue', 'hostile', 'unexpectedly', 'board', 'mix', 'turn', 'limit', 'delay', 'omit', 'disrupt', 'block', 'dependent', 'insufficient', 'matter', 'oversight', 'uncertainty'}\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "#Let's get Apple's SEC filing 10K\n",
    "url = 'http://investor.apple.com/secfiling.cfm?filingID=320193-17-70&CIK=320193'\n",
    "finScore(url,poswords,negwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'integrity', 'comprehensive', 'unlimited', 'enhance', 'accordance', 'travel', 'indicative', 'reward', 'relevant', 'favorable', 'supreme', 'award', 'particular', 'achieve', 'secure', 'justice', 'continuity', 'competence', 'persuasive', 'offer', 'pro', 'credit', 'complement', 'acceptable', 'safe', 'adjustment', 'maturity', 'success', 'useful', 'interest', 'attract', 'protect', 'responsibility', 'create', 'principal', 'allowance', 'relief', 'home', 'conjunction', 'even', 'best', 'major', 'have', 'law', 'aggregate', 'their', 'her', 'security', 'sensitivity', 'intelligent', 'profit', 'essential', 'important', 'support', 'effectiveness', 'fitness', 'educational', 'guarantee', 'asset', 'gain', 'renewal', 'responsible', 'commitment', 'compliance', 'assist', 'effective', 'portable', 'knowledge', 'upgrade', 'help', 'capability', 'actual', 'compensation', 'bonus', 'free', 'behalf', 'protection', 'commission', 'devote', 'productivity', 'allow', 'better', 'enable', 'contribution', 'privacy', 'definitive', 'merit', 'basic', 'trust', 'mutual', 'company', 'advance', 'consistent', 'practical', 'redemption', 'open', 'offset', 'ensure', 'adjust', 'communicate', 'dynamic', 'respect', 'assurance', 'lead', 'partner', 'consider', 'objective', 'normal', 'benefit', 'satisfy', 'traditional', 'desirable', 'generate', 'successful', 'permit', 'solution', 'adequate', 'attractive', 'suitable', 'collaborate', 'equity', 'redeem', 'repair', 'awareness', 'approval', 'settle', 'safety', 'quality', 'agreement', 'well', 'natural', 'share', 'community', 'utilize', 'our', 'sufficient', 'superior', 'resolved', 'intellectual', 'aid', 'reasonable', 'sophisticated', 'super', 'gift', 'forward', 'advantage', 'make', 'good', 'outstanding', 'return', 'achievement', 'content', 'appropriate', 'reliability', 'experience', 'virtue', 'buy', 'reconciliation', 'pay', 'favor', 'innovative', 'fair', 'proactive', 'reconcile', 'appreciation', 'logic', 'legal', 'obtain', 'approach', 'meaningful', 'improvement', 'order', 'resolve', 'common', 'assistance', 'education', 'confidence', 'compatible', 'unique', 'premium', 'reliable', 'qualify', 'subsidize', 'understand', 'simplify', 'capacity', 'health', 'right', 'stimulate', 'sensitive', 'value', 'primarily', 'necessarily', 'advantageous', 'board', 'jointly', 'meet', 'provide', 'conclusive', 'availability', 'real', 'arisen', 'contact', 'his', 'significant', 'positive', 'beneficial', 'matter', 'independent', 'improve', 'post', 'my', 'authority'}\n",
      "213\n",
      "{'lose', 'restrict', 'unlimited', 'loss', 'capital', 'exception', 'decline', 'mine', 'impossible', 'particular', 'unqualified', 'serve', 'unforeseen', 'withheld', 'competitive', 'against', 'disruption', 'violation', 'poor', 'compete', 'unable', 'least', 'nor', 'service', 'violate', 'risky', 'even', 'uncertain', 'instability', 'impede', 'shell', 'volatile', 'rather', 'foreign', 'differ', 'competition', 'suffer', 'cancellation', 'damage', 'interruption', 'no', 'force', 'severe', 'help', 'fix', 'disaster', 'expense', 'cut', 'defect', 'indefinite', 'negative', 'decrease', 'adverse', 'impair', 'close', 'doubtful', 'harm', 'press', 'turmoil', 'difficult', 'malicious', 'intangible', 'lost', 'redundancy', 'interfere', 'liability', 'execute', 'vice', 'failure', 'expose', 'complex', 'point', 'division', 'infringement', 'unfavorable', 'low', 'not', 'stringent', 'distracting', 'cost', 'terrorism', 'abrupt', 'excess', 'unconditional', 'accident', 'breach', 'delinquent', 'ineffective', 'obsolete', 'make', 'distraction', 'dissatisfied', 'unusual', 'indirect', 'tax', 'avoid', 'depreciation', 'volatility', 'shortage', 'raise', 'lower', 'need', 'prohibitive', 'order', 'unexpected', 'liable', 'cannot', 'aggressive', 'fall', 'charge', 'involve', 'inadequate', 'neither', 'show', 'short', 'unpredictable', 'hedge', 'unspecified', 'inability', 'discount', 'suspicious', 'hostile', 'unexpectedly', 'board', 'mix', 'turn', 'limit', 'delay', 'disrupt', 'insufficient', 'matter', 'oversight', 'uncertainty'}\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "#Repeat with a different URL from the SEC\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/320193/000032019317000070/a10-k20179302017.htm'\n",
    "finScore(url,poswords,negwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The results are different, n0t sure why this is so!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech (POS) Tagging\n",
    "\n",
    "https://www.cs.toronto.edu/~frank/csc2501/Tutorials/cs485_nltk_krish_tutorial1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
